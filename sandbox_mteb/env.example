# =========================================================================
# sandbox_mteb/.env
# RAG_P v3.2 - Configuracion completa de un run de evaluacion
# =========================================================================
# Toda la parametrizacion del run se define aqui.
# MTEBConfig.from_env() lo lee una sola vez al inicio.

# =========================================================================
# EMBEDDING (NIM)
# =========================================================================
EMBEDDING_MODEL_NAME=nvidia/llama-3.2-nv-embedqa-1b-v2
EMBEDDING_BASE_URL=http://172.30.79.98:8000/v1
EMBEDDING_MODEL_TYPE=asymmetric
# Batch size para indexacion de embeddings. Default=50.
# Reducir si el NIM de embeddings tiene poca memoria.
EMBEDDING_BATCH_SIZE=5

# =========================================================================
# LLM (NIM) - generacion + LLM-judge + enriquecimiento contextual
# =========================================================================
LLM_BASE_URL=http://172.30.79.99:8000/v1
LLM_MODEL_NAME=nvidia/nemotron-3-nano

# Concurrencia y reintentos contra NIM.
# ATENCION: las variables son NIM_MAX_CONCURRENT_REQUESTS y NIM_REQUEST_TIMEOUT
# (no NIM_MAX_CONCURRENT ni NIM_TIMEOUT).
NIM_MAX_CONCURRENT_REQUESTS=32
NIM_REQUEST_TIMEOUT=120
NIM_MAX_RETRIES=3

# =========================================================================
# RETRIEVAL
# =========================================================================
# Estrategias validas: SIMPLE_VECTOR, CONTEXTUAL_HYBRID
RETRIEVAL_STRATEGY=SIMPLE_VECTOR

# Docs recuperados para calcular metricas de retrieval (pre-rerank).
RETRIEVAL_K=20

# Pesos para fusion RRF (solo CONTEXTUAL_HYBRID).
RETRIEVAL_BM25_WEIGHT=0.5
RETRIEVAL_VECTOR_WEIGHT=0.5

# Candidatos pre-fusion para BM25 y vector por separado.
RETRIEVAL_PRE_FUSION_K=150

# Parametro k de Reciprocal Rank Fusion.
RETRIEVAL_RRF_K=60

# Idioma del stemmer BM25 (Tantivy Snowball): en, es, de, fr, it, pt, ...
RETRIEVAL_BM25_LANGUAGE=en

# Threads para construccion del grafo HNSW (ChromaDB). 1 = determinista
# (reproducible entre runs). Valores > 1 aceleran indexacion pero el
# no-determinismo de threading produce resultados ligeramente diferentes.
# ChromaDB 0.5-0.6 no soporta hnsw:random_seed.
HNSW_NUM_THREADS=1

# =========================================================================
# CONTEXTUAL RETRIEVAL (solo si RETRIEVAL_STRATEGY=CONTEXTUAL_HYBRID)
# =========================================================================
# Max tokens para el contexto generado por el LLM al enriquecer cada doc.
RETRIEVAL_CONTEXT_MAX_TOKENS=150

# Batch size para enriquecimiento contextual (docs procesados en paralelo).
RETRIEVAL_CONTEXT_BATCH_SIZE=10

# =========================================================================
# RERANKER (cross-encoder, opcional)
# =========================================================================
RERANKER_ENABLED=true
RERANKER_BASE_URL=http://172.30.79.98:9000/v1
RERANKER_MODEL_NAME=nvidia/llama-3.2-nv-rerankqa-1b-v2
# Docs pasados al LLM para generacion tras reranking.
RERANKER_TOP_N=5

# =========================================================================
# DATASET Y EVALUACION
# =========================================================================
MTEB_DATASET_NAME=hotpotqa

# 0 = usar todas las queries / todo el corpus.
EVAL_MAX_QUERIES=0
EVAL_MAX_CORPUS=0

GENERATION_ENABLED=true

# Limite de caracteres para contexto de generacion.
# 0 = auto-derivar del context window del modelo via GET /v1/models.
#     Formula: (max_model_len - 1024 overhead) * 4.0 chars/token.
# >0 = override manual en caracteres.
GENERATION_MAX_CONTEXT_CHARS=0

# Seed para shuffle del corpus antes de slice.
# Evita sesgo de orden (corpus alineado con queries en Parquet).
# -1 = desactivar shuffle (NO recomendado).
CORPUS_SHUFFLE_SEED=42

# =========================================================================
# MODO DESARROLLO
# =========================================================================
# Subset inteligente: selecciona N queries y garantiza sus gold docs
# en el corpus, rellenando con distractores aleatorios.
# Ignora EVAL_MAX_QUERIES y EVAL_MAX_CORPUS cuando esta activo.
# Metricas NO comparables con runs completos (ratio gold/distractores elevado).
DEV_MODE=false
DEV_QUERIES=200
DEV_CORPUS_SIZE=4000

# =========================================================================
# MINIO (S3-compatible)
# =========================================================================
MINIO_ENDPOINT=http://172.30.79.110:9000
MINIO_ACCESS_KEY=minioadmin
MINIO_SECRET_KEY=minio123
MINIO_BUCKET_NAME=lakehouse
S3_DATASETS_PREFIX=datasets/evaluation

# =========================================================================
# PATHS (relativos al directorio de ejecucion)
# =========================================================================
DATASETS_CACHE_DIR=./data/datasets_cache
EVALUATION_RESULTS_DIR=./data/results
VECTOR_DB_DIR=./data/vector_db
